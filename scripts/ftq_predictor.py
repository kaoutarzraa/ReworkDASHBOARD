import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score
import json
import datetime
import warnings
warnings.filterwarnings('ignore')

class FTQPredictor:
    """
    Pr√©dicteur FTQ utilisant Random Forest avec scikit-learn
    Concepts ML : Feature Engineering, Random Forest, Cross-validation
    """
    
    def __init__(self):
        self.model = RandomForestRegressor(
            n_estimators=100,      # 100 arbres dans la for√™t
            max_depth=10,          # Profondeur maximale des arbres
            min_samples_split=5,   # Minimum d'√©chantillons pour diviser un n≈ìud
            min_samples_leaf=2,    # Minimum d'√©chantillons dans une feuille
            random_state=42,       # Pour la reproductibilit√©
            n_jobs=-1             # Utiliser tous les processeurs
        )
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.is_trained = False
        
    def load_data(self, json_file_path):
        """
        Charger et pr√©processer les donn√©es de d√©fauts
        """
        try:
            with open(json_file_path, 'r') as f:
                data = json.load(f)
            
            df = pd.DataFrame(data)
            print(f"üìä Donn√©es charg√©es: {len(df)} d√©fauts")
            return df
        except Exception as e:
            print(f"‚ùå Erreur chargement donn√©es: {e}")
            return self.generate_synthetic_data()
    
    def generate_synthetic_data(self, n_samples=1000):
        """
        G√©n√©rer des donn√©es synth√©tiques r√©alistes pour l'entra√Ænement
        """
        print("üîÑ G√©n√©ration de donn√©es synth√©tiques...")
        
        np.random.seed(42)
        data = []
        
        for i in range(n_samples):
            # Simuler des donn√©es r√©alistes
            hour = np.random.randint(0, 24)
            day_of_week = np.random.randint(0, 7)
            area = np.random.choice(['Motor', 'Interior'])
            line = np.random.choice(['L1', 'L2', 'L3'])
            defect_type = np.random.choice(['Terminal', 'Connecteur', 'S√©curit√©', 'Autre'])
            
            # Temps de rework influenc√© par le type de d√©faut
            base_time = {'Terminal': 35, 'Connecteur': 50, 'S√©curit√©': 40, 'Autre': 30}
            rework_time = base_time[defect_type] + np.random.normal(0, 10)
            rework_time = max(15, min(120, rework_time))  # Borner entre 15-120 min
            
            # Date al√©atoire dans les 30 derniers jours
            date = datetime.datetime.now() - datetime.timedelta(
                days=np.random.randint(0, 30),
                hours=hour,
                minutes=np.random.randint(0, 60)
            )
            
            data.append({
                'ORDNR': f'ORD{i+1:04d}',
                'Area': area,
                'Line': line,
                'REWORK_DATE': date.isoformat(),
                'Rework_time': round(rework_time),
                'defect_type': defect_type
            })
        
        return pd.DataFrame(data)
    
    def feature_engineering(self, df):
        """
        Ing√©nierie des caract√©ristiques (Feature Engineering)
        """
        print("üîß Feature Engineering...")
        
        # Convertir la date
        df['REWORK_DATE'] = pd.to_datetime(df['REWORK_DATE'])
        
        # Extraire les caract√©ristiques temporelles
        df['hour'] = df['REWORK_DATE'].dt.hour
        df['day_of_week'] = df['REWORK_DATE'].dt.dayofweek
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        df['is_night_shift'] = ((df['hour'] >= 22) | (df['hour'] <= 6)).astype(int)
        
        # Encoder les variables cat√©gorielles
        categorical_features = ['Area', 'Line', 'defect_type']
        for feature in categorical_features:
            if feature not in self.label_encoders:
                self.label_encoders[feature] = LabelEncoder()
                df[f'{feature}_encoded'] = self.label_encoders[feature].fit_transform(df[feature])
            else:
                df[f'{feature}_encoded'] = self.label_encoders[feature].transform(df[feature])
        
        # Statistiques par ligne de production
        line_stats = df.groupby(['Area', 'Line']).agg({
            'Rework_time': ['mean', 'std', 'count']
        }).round(2)
        
        # Ajouter des features d'interaction
        df['area_line'] = df['Area'] + '_' + df['Line']
        df['defect_severity'] = df['Rework_time'] / df['Rework_time'].mean()
        
        # Features pour la pr√©diction
        feature_columns = [
            'hour', 'day_of_week', 'is_weekend', 'is_night_shift',
            'Area_encoded', 'Line_encoded', 'defect_type_encoded',
            'Rework_time', 'defect_severity'
        ]
        
        return df, feature_columns
    
    def calculate_ftq_target(self, df, production_target=1000):
        """
        Calculer le FTQ cible bas√© sur les d√©fauts
        """
        # Grouper par jour pour calculer le FTQ quotidien
        daily_defects = df.groupby(df['REWORK_DATE'].dt.date).size()
        daily_ftq = ((production_target/30 - daily_defects) / (production_target/30) * 100).clip(85, 98)
        
        # Mapper le FTQ √† chaque d√©faut
        df['date_only'] = df['REWORK_DATE'].dt.date
        ftq_mapping = daily_ftq.to_dict()
        df['ftq_target'] = df['date_only'].map(ftq_mapping)
        
        return df
    
    def train_model(self, df):
        """
        Entra√Æner le mod√®le Random Forest
        """
        print("üå≤ Entra√Ænement du mod√®le Random Forest...")
        
        # Feature engineering
        df, feature_columns = self.feature_engineering(df)
        
        # Calculer les cibles FTQ
        df = self.calculate_ftq_target(df)
        
        # Pr√©parer les donn√©es
        X = df[feature_columns]
        y = df['ftq_target']
        
        # Division train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Normalisation des features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Entra√Ænement du Random Forest
        self.model.fit(X_train_scaled, y_train)
        
        # √âvaluation
        y_pred = self.model.predict(X_test_scaled)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        print(f"‚úÖ Mod√®le entra√Æn√©:")
        print(f"   - MSE: {mse:.2f}")
        print(f"   - R¬≤: {r2:.3f}")
        print(f"   - Features: {len(feature_columns)}")
        
        # Importance des features
        feature_importance = pd.DataFrame({
            'feature': feature_columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nüìä Importance des features:")
        for _, row in feature_importance.head().iterrows():
            print(f"   - {row['feature']}: {row['importance']:.3f}")
        
        self.feature_columns = feature_columns
        self.is_trained = True
        
        return {
            'mse': mse,
            'r2': r2,
            'feature_importance': feature_importance.to_dict('records')
        }
    
    def predict_ftq(self, current_defects_data):
        """
        Pr√©dire le FTQ bas√© sur les donn√©es actuelles
        """
        if not self.is_trained:
            print("‚ùå Mod√®le non entra√Æn√©!")
            return None
        
        print("üîÆ Pr√©diction FTQ en cours...")
        
        # Convertir en DataFrame si n√©cessaire
        if isinstance(current_defects_data, list):
            df_current = pd.DataFrame(current_defects_data)
        else:
            df_current = current_defects_data.copy()
        
        # Feature engineering sur les donn√©es actuelles
        df_current, _ = self.feature_engineering(df_current)
        
        # Calculer les m√©triques actuelles
        total_defects = len(df_current)
        avg_rework_time = df_current['Rework_time'].mean()
        
        # Cr√©er les features pour la pr√©diction
        current_time = datetime.datetime.now()
        
        # Features moyennes des donn√©es actuelles
        features = np.array([[
            current_time.hour,                                    # hour
            current_time.weekday(),                              # day_of_week
            1 if current_time.weekday() >= 5 else 0,            # is_weekend
            1 if current_time.hour >= 22 or current_time.hour <= 6 else 0,  # is_night_shift
            df_current['Area_encoded'].mode()[0] if len(df_current) > 0 else 0,  # Area_encoded
            df_current['Line_encoded'].mode()[0] if len(df_current) > 0 else 0,  # Line_encoded
            df_current['defect_type_encoded'].mode()[0] if len(df_current) > 0 else 0,  # defect_type_encoded
            avg_rework_time,                                     # Rework_time
            1.0                                                  # defect_severity
        ]])
        
        # Normaliser et pr√©dire
        features_scaled = self.scaler.transform(features)
        predicted_ftq = self.model.predict(features_scaled)[0]
        
        # Calculer le FTQ actuel
        production_target = 1000
        current_ftq = ((production_target - total_defects) / production_target * 100)
        current_ftq = max(85, min(98, current_ftq))
        
        # Calculer la confiance (bas√©e sur la variance des pr√©dictions des arbres)
        tree_predictions = [tree.predict(features_scaled)[0] for tree in self.model.estimators_]
        confidence = 1 - (np.std(tree_predictions) / np.mean(tree_predictions))
        confidence = max(0.7, min(0.95, confidence))
        
        # Analyser les lignes les plus/moins performantes
        line_analysis = self.analyze_production_lines(df_current)
        
        result = {
            'current_ftq': round(current_ftq, 1),
            'predicted_ftq': round(predicted_ftq, 1),
            'confidence': round(confidence, 3),
            'total_defects': total_defects,
            'avg_rework_time': round(avg_rework_time, 1),
            'improvement': round(predicted_ftq - current_ftq, 1),
            'line_analysis': line_analysis,
            'model_info': {
                'algorithm': 'Random Forest',
                'n_estimators': self.model.n_estimators,
                'max_depth': self.model.max_depth,
                'features_used': len(self.feature_columns)
            }
        }
        
        print(f"üéØ Pr√©diction termin√©e:")
        print(f"   - FTQ actuel: {result['current_ftq']}%")
        print(f"   - FTQ pr√©dit: {result['predicted_ftq']}%")
        print(f"   - Confiance: {result['confidence']*100:.1f}%")
        
        return result
    
    def analyze_production_lines(self, df):
        """
        Analyser les performances par ligne de production
        """
        if len(df) == 0:
            return {
                'best_motor_line': 'Motor L1',
                'worst_motor_line': 'Motor L2',
                'best_interior_line': 'Interior L1',
                'worst_interior_line': 'Interior L3'
            }
        
        # Analyser par zone et ligne
        line_stats = df.groupby(['Area', 'Line']).agg({
            'Rework_time': ['count', 'mean']
        }).round(2)
        
        # S√©parer Motor et Interior
        motor_lines = df[df['Area'] == 'Motor'].groupby('Line')['Rework_time'].count()
        interior_lines = df[df['Area'] == 'Interior'].groupby('Line')['Rework_time'].count()
        
        # Identifier les meilleures/pires lignes (moins de d√©fauts = mieux)
        best_motor = motor_lines.idxmin() if len(motor_lines) > 0 else 'L1'
        worst_motor = motor_lines.idxmax() if len(motor_lines) > 0 else 'L2'
        
        best_interior = interior_lines.idxmin() if len(interior_lines) > 0 else 'L1'
        worst_interior = interior_lines.idxmax() if len(interior_lines) > 0 else 'L3'
        
        return {
            'best_motor_line': f'Motor {best_motor}',
            'worst_motor_line': f'Motor {worst_motor}',
            'best_interior_line': f'Interior {best_interior}',
            'worst_interior_line': f'Interior {worst_interior}'
        }

# Fonction principale pour ex√©cuter la pr√©diction
def main():
    """
    Fonction principale pour tester le pr√©dicteur FTQ
    """
    print("üöÄ D√©marrage du pr√©dicteur FTQ avec Python ML")
    print("=" * 50)
    
    # Initialiser le pr√©dicteur
    predictor = FTQPredictor()
    
    # Charger les donn√©es (ou g√©n√©rer des donn√©es synth√©tiques)
    try:
        # Essayer de charger les vraies donn√©es
        df = predictor.load_data('public/backend/data/data.json')
    except:
        # Utiliser des donn√©es synth√©tiques
        df = predictor.generate_synthetic_data(800)
    
    # Entra√Æner le mod√®le
    training_results = predictor.train_model(df)
    
    # Simuler des donn√©es actuelles pour la pr√©diction
    current_defects = df.tail(50).to_dict('records')  # Derniers 50 d√©fauts
    
    # Faire la pr√©diction
    prediction = predictor.predict_ftq(current_defects)
    
    if prediction:
        print("\n" + "=" * 50)
        print("üìä R√âSULTATS DE LA PR√âDICTION FTQ")
        print("=" * 50)
        print(f"üéØ FTQ Actuel: {prediction['current_ftq']}%")
        print(f"üîÆ FTQ Pr√©dit: {prediction['predicted_ftq']}%")
        print(f"üìà Am√©lioration: {prediction['improvement']:+.1f}%")
        print(f"üé≤ Confiance: {prediction['confidence']*100:.1f}%")
        print(f"üîß D√©fauts analys√©s: {prediction['total_defects']}")
        print(f"‚è±Ô∏è  Temps moyen rework: {prediction['avg_rework_time']:.1f} min")
        
        print(f"\nüèÜ Lignes les plus performantes:")
        print(f"   - {prediction['line_analysis']['best_motor_line']}")
        print(f"   - {prediction['line_analysis']['best_interior_line']}")
        
        print(f"\n‚ö†Ô∏è  Lignes √† am√©liorer:")
        print(f"   - {prediction['line_analysis']['worst_motor_line']}")
        print(f"   - {prediction['line_analysis']['worst_interior_line']}")
        
        print(f"\nü§ñ Mod√®le utilis√©:")
        print(f"   - Algorithme: {prediction['model_info']['algorithm']}")
        print(f"   - Nombre d'arbres: {prediction['model_info']['n_estimators']}")
        print(f"   - Profondeur max: {prediction['model_info']['max_depth']}")
        print(f"   - Features: {prediction['model_info']['features_used']}")
        
        # Recommandations bas√©es sur les r√©sultats
        print(f"\nüí° RECOMMANDATIONS:")
        if prediction['current_ftq'] < 95:
            print("   üö® ALERTE: FTQ en dessous du seuil critique de 95%")
            print(f"   üéØ Concentrer les efforts sur {prediction['line_analysis']['worst_motor_line']}")
            print(f"   üéØ Am√©liorer les processus de {prediction['line_analysis']['worst_interior_line']}")
        else:
            print("   ‚úÖ FTQ dans les objectifs")
            print(f"   üìã Maintenir les bonnes pratiques de {prediction['line_analysis']['best_motor_line']}")
        
        if prediction['improvement'] > 0:
            print(f"   üìà Am√©lioration pr√©vue de {prediction['improvement']:.1f}% possible")
        else:
            print(f"   üìâ Risque de d√©gradation de {abs(prediction['improvement']):.1f}%")
    
    print("\n‚úÖ Analyse termin√©e!")
    return prediction

# Ex√©cuter le script
if __name__ == "__main__":
    result = main()
